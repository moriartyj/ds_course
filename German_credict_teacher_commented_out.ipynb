{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import io, os , sys, types\n",
    "import tabulate\n",
    "import copy\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import tree\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pydotplus\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "from helper_functions import *\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "fontsz = 12\n",
    "\n",
    "# ROC Curve and Cutoff Analysis:\n",
    "# https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/One_ROC_Curve_and_Cutoff_Analysis.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dataset (L)\n",
    "fname_germancredit = r'dataset/German.Credit.csv'\n",
    "data_raw = pd.read_csv(fname_germancredit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (L)\n",
    "col_target = 'class'\n",
    "cols_numeric = list(data_raw.describe().columns.values)\n",
    "cols_categoric = list(set(data_raw.columns.values) - set(cols_numeric) - set([col_target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data describe\n",
    "if False:\n",
    "    data_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display categoric columns\n",
    "if False:\n",
    "    display(cols_categoric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contingency table (crosstab)\n",
    "if False:\n",
    "    pd.crosstab(data_raw['class'], data_raw['account_balance'],  margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contingency table, ratios. Rows add-up to 100%\n",
    "if False:\n",
    "    pd.crosstab(data_raw['class'], data_raw['account_balance'],  margins=False, normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contingency table, ratios. Columns add-up to 100%\n",
    "if False:\n",
    "    pd.crosstab(data_raw['class'], data_raw['account_balance'],  margins=False, normalize='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and print p-value from contingency table\n",
    "if False:\n",
    "    contingency = pd.crosstab(data_raw['class'], data_raw['account_balance'])\n",
    "    c, pval, dof, expected = chi2_contingency(contingency)\n",
    "    print(\"p-value:\",pval, '\\t variable:', 'account_balance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do so for all predictors\n",
    "if False:\n",
    "    for col in cols_categoric:\n",
    "        contingency = pd.crosstab(data_raw['class'], data_raw[col])\n",
    "        c, pval, dof, expected = chi2_contingency(contingency)\n",
    "        print(\"p-value:\",pval, '\\t variable:', col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics for Numerical Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix\n",
    "Correlation between numeric variables. Plot the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (L)\n",
    "data_numeric = data_raw[cols_numeric].copy(deep=True)\n",
    "corr_mat = data_numeric.corr(method='pearson')\n",
    "cbar_ticks =np.linspace(-1,1,11)\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "plt.figure(figsize=[8,8])\n",
    "plt.xticks(fontsize=fontsz+2)\n",
    "plt.yticks(fontsize=fontsz+2)\n",
    "ax = sns.heatmap(corr_mat, cmap=cmap, vmin=-1, vmax=1, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.set_ticks(cbar_ticks)\n",
    "cbar.set_ticklabels(cbar_ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the correlation matrix (just the numbers, not a figure)\n",
    "print (tabulate.tabulate(corr_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    brksCredits = np.linspace(0,80,11) # Bins for a nice looking histogram\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.hist(data_raw['duration'], bins=brksCredits)\n",
    "    plt.title('duration', fontsize=fontsz+4)\n",
    "    plt.xlabel('Loan Period [Months]', fontsize=fontsz+2)\n",
    "    plt.ylabel('Count', fontsize=fontsz+2)\n",
    "    plt.xticks(fontsize=fontsz)\n",
    "    plt.yticks(fontsize=fontsz)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.boxplot(data_raw['duration']) \n",
    "    plt.title('duration boxplot', fontsize=fontsz+4)\n",
    "    plt.xlabel('Credit Month', fontsize=fontsz+2) \n",
    "    plt.ylabel('duration', fontsize=fontsz+2)\n",
    "    plt.xticks(fontsize=fontsz)\n",
    "    plt.yticks(fontsize=fontsz)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Creating dummy-variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace categorical variables with dummy-variables\n",
    "if False:\n",
    "    print (\"Number of columns before dummy-variables:\\t\", len(data_raw.columns.values))\n",
    "    for i in cols_categoric:\n",
    "        dummy_ranks = pd.get_dummies(data_raw[i], prefix=i)\n",
    "        data_raw = data_raw.join(dummy_ranks)\n",
    "        # dropping the original categoric column (not needed - it was replaced by dummy columns)\n",
    "        data_raw = data_raw.drop(i, 1) \n",
    "\n",
    "    # all feature, numeric, and categoric (now dummified)\n",
    "    cols_features = list(set(data_raw.columns.values) - set([col_target])) \n",
    "    print (\"Number of columns after dummy-variables:\\t\", len(data_raw.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace ‘bad’ and ‘good’ class labels with 0 and 1, before continuing with the exercise\n",
    "if False:\n",
    "    data_raw['class'].replace('bad', 0, inplace=True)\n",
    "    data_raw['class'].replace('good', 1, inplace=True)\n",
    "    data_raw['class'] = pd.to_numeric(data_raw['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#(L)\n",
    "# Random seed\n",
    "seed = 1017\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(L)\n",
    "# Split the data using the function, train_test_split()\n",
    "frac_train = 0.8 # 80% of the data is used for training\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(data_raw[cols_features], data_raw[col_target], test_size=(1-frac_train), random_state=seed)\n",
    "    \n",
    "train_b = sum(y_train == 0)\n",
    "train_g = sum(y_train == 1)\n",
    "test_b = sum(y_test == 0)\n",
    "test_g = sum(y_test == 1)\n",
    "print (\"Class ratios between each set:\")\n",
    "print (\"Trainset\")\n",
    "print (\"\\t\\tNormal class (good):\", 100*train_g/len(y_train), \"%\\t\", \"Target class (bad):\", 100*train_b/len(y_train),\"%\")\n",
    "print (\"Testset\")\n",
    "print (\"\\t\\tNormal class (good):\", 100*test_g/len(y_test), \"%\\t\", \"Target class (bad):\", 100*test_b/len(y_test),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set Misclassification loss weights\n",
    "c_tn = 0 # weight of true-negative\n",
    "c_tp = 0 # weight of true-positive\n",
    "c_fn = 1 # weight of false negative\n",
    "c_fp = 5 # weight of false positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model\n",
    "More about Logistic Regression examples in python can be found here:<br>\n",
    "They are using a different (and more informative) logistic-regression package<br>\n",
    "http://blog.yhat.com/posts/logistic-regression-python-rodeo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Train the model\n",
    "if False:\n",
    "    model = linear_model.LogisticRegression()\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (L)\n",
    "mse = np.mean(y_train - model.predict(X_train)) ** 2\n",
    "print (\"Mean Square Error: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. Display the obtained model along with most relevant statistics\n",
    "if False:\n",
    "    model_coefficients = model.coef_[0]\n",
    "    df_lgm_coeffs = pd.DataFrame(data=[list(cols_features), list(model_coefficients)]).transpose()\n",
    "    df_lgm_coeffs.columns = ['feature', 'LGM_coeff']\n",
    "    # sort by coefficients absolute value\n",
    "    df_lgm_coeffs = df_lgm_coeffs.reindex(df_lgm_coeffs['LGM_coeff'].abs().sort_values(inplace=False, ascending=False).index)\n",
    "    display(df_lgm_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. Test the model\n",
    "if False:\n",
    "    predicted = model.predict(X_test)\n",
    "    predicted_prob = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Draw ROC Curve and calculate AUC\n",
    "if False:\n",
    "    fpr, tpr, _ = metrics.roc_curve(np.array(y_test), predicted_prob)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "    print (\"Area-Under-Curve:\", round(auc,4))\n",
    "    # plot_ROC() is defined in helper_functions.py\n",
    "    plot_ROC(fpr,tpr, fontsz, 'Receiver operating characteristic for Logistic Regression Model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Calculate the total misclassification loss\n",
    "if False:\n",
    "    train_predicted_prob = model.predict_proba(X_train)[:,1]\n",
    "    loss_matrix = calculate_loss(train_predicted_prob, y_train, c_fn, c_fp, c_tp, c_tn) \n",
    "    # finding optimal threshold:\n",
    "    opt_thr = list(loss_matrix[loss_matrix['loss'] == loss_matrix['loss'].min()]['prediction'])[0]\n",
    "    print(\"Optimal threshold at:\\t\",round(opt_thr,5))\n",
    "    print(\"Model Loss:\", loss_matrix['loss'].min())\n",
    "    loss = loss_matrix['loss'].min()\n",
    "    predicted_prob_opt = copy.deepcopy(predicted_prob)\n",
    "    predicted_prob_opt[predicted_prob_opt >  opt_thr] = 1\n",
    "    predicted_prob_opt[predicted_prob_opt <= opt_thr] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6. Build the confusion matrix for the tests data for both the default and optimal thresholds\n",
    "if False:\n",
    "    def_cfm = metrics.confusion_matrix(y_test, predicted) # default confusion matrix, default threshold = 0.5\n",
    "    opt_cfm = metrics.confusion_matrix(y_test, predicted_prob_opt) # optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Plot the confusion matrices\n",
    "if False:\n",
    "    plot_confusion_matrix(def_cfm,['bad', 'good'], \"Default Confusion Matrix\", 0)\n",
    "    plot_confusion_matrix(opt_cfm,['bad', 'good'], \"Loss-Optimized Confusion Matrix\", 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Optional]: Plot the misclassification-loss vs threshold\n",
    "if False:\n",
    "    plt.figure(figsize=(10,5), facecolor='white')\n",
    "    plt.plot(loss_matrix['prediction'], loss_matrix['loss'], 'o-')\n",
    "    plt.title('Loss function for various thresholds and confusion matrices', fontsize=fontsz+4)\n",
    "    plt.xlabel('Threshold', fontsize=fontsz+4)\n",
    "    plt.ylabel('Loss', fontsize=fontsz+4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Train the model and apply predictions\n",
    "if False:\n",
    "    gnb = BernoulliNB()\n",
    "    model = gnb.fit(X_train, y_train)\n",
    "    predicted = model.predict(X_test)\n",
    "    predicted_prob = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. Display the obtained model along with most relevant statistics\n",
    "if False:\n",
    "    model_coefficients = model.coef_[0]\n",
    "    df_coeffs = pd.DataFrame(data=[list(cols_features), list(model_coefficients)]).transpose()\n",
    "    df_coeffs.columns = ['feature', 'coeff']\n",
    "    # sort by coefficients absolute value (log probability of the positive class)\n",
    "    df_coeffs = df_coeffs.reindex(df_coeffs['coeff'].abs().sort_values(inplace=False, ascending=True).index)\n",
    "    display(df_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Draw ROC Curve and calculate AUC\n",
    "if False:\n",
    "    fpr, tpr, _ = metrics.roc_curve(np.array(y_test), predicted_prob)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "    print (\"Area-Under-Curve:\", round(auc,4))\n",
    "    plot_ROC(fpr,tpr, fontsz, 'Receiver operating characteristic for Naive Bayes Model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Calculate the total misclassification loss\n",
    "if False:\n",
    "    # finding the optimal values using the TRAIN-SET\n",
    "    train_predicted_prob = model.predict_proba(X_train)[:,1]\n",
    "    loss_matrix = calculate_loss(train_predicted_prob, y_train, c_fn, c_fp, c_tp, c_tn) \n",
    "    # finding optimal threshold:\n",
    "    opt_thr = list(loss_matrix[loss_matrix['loss'] == loss_matrix['loss'].min()]['prediction'])[0]\n",
    "    print(\"Optimal threshold at:\\t\",round(opt_thr,5))\n",
    "    loss = loss_matrix['loss'].min()\n",
    "    print(\"Model Loss:\", loss)\n",
    "    predicted_prob_opt = copy.deepcopy(predicted_prob)\n",
    "    predicted_prob_opt[predicted_prob_opt >  opt_thr] = 1\n",
    "    predicted_prob_opt[predicted_prob_opt <= opt_thr] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6. Build the confusion matrix for the tests data for both the default and optimal thresholds\n",
    "if False:\n",
    "    def_cfm = metrics.confusion_matrix(y_test, predicted) \n",
    "    opt_cfm = metrics.confusion_matrix(y_test, predicted_prob_opt) # optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Plot the confusion matrices\n",
    "if False:\n",
    "    plot_confusion_matrix(def_cfm,['bad', 'good'], \"Default Confusion Matrix\", 0)\n",
    "    plot_confusion_matrix(opt_cfm,['bad', 'good'], \"Loss-Optimized Confusion Matrix\", 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "Decision Trees is a recursive-repartitioning technique, which is used to recursively split the data in order to create nodes that are<br>\n",
    "purer. A pure node is a node that consists of only 1-class of those existing in the data.<br>\n",
    "In our context, a pure node would be composed of either all-\"bad\" or all-\"good\" classes.<br>\n",
    "The advantages of DT is that it produces rules that are easy to follow, and human-readable, in contrast to other \"black-box\" algorithms, such as Random-Forest<br>\n",
    "DTs however, are prone to overfitting, which is why we need to use some parameters to avoid such behavior.<br>\n",
    "As with __Logistic Regression__, __DT__s also require categorical features to be dummified.<br>\n",
    "1. Based on what we discussed, can you offer an intuition about why DTs tend to overfit?\n",
    "2. [Advanced] Can you offer some ways to avoid overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (L)\n",
    "# 1. Train the model and apply predictions\n",
    "md = 18                    # maximum tree depth\n",
    "mf = len(cols_features)    # maximum number of features to consider\n",
    "min_leaf = 10\n",
    "criterion = 'entropy'\n",
    "model = tree.DecisionTreeClassifier(max_depth=md, max_features=mf, criterion=criterion, \n",
    "                                    min_samples_leaf=min_leaf, random_state=seed)\n",
    "\n",
    "clf = model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "predicted_prob = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. Display the obtained model along with most relevant statistics\n",
    "if False:\n",
    "    importance = model.feature_importances_\n",
    "    df_importance = pd.DataFrame(data=[list(cols_features), list(importance)]).transpose()\n",
    "    df_importance.columns = ['feature', 'importance']\n",
    "    df_importance = df_importance[df_importance['importance'] != 0]\n",
    "    # sort by feature importance\n",
    "    df_importance = df_importance.reindex(df_importance['importance'].abs().sort_values(inplace=False, ascending=False).index)\n",
    "    display(df_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize the tree\n",
    "##write_Tree('dataset', clf, cols_features) # can be used only for small trees (<=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Draw ROC Curve and calculate AUC\n",
    "if False:\n",
    "    fpr, tpr, _ = metrics.roc_curve(np.array(y_test), predicted_prob)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "    print (\"Area-Under-Curve:\", round(auc,4))\n",
    "    plot_ROC(fpr,tpr, fontsz, \"Receiver operating characteristic for Decision Tree Model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Calculate the total misclassification loss\n",
    "if False:\n",
    "    # finding the optimal values using the TRAIN-SET\n",
    "    train_predicted_prob = model.predict_proba(X_train)[:,1]\n",
    "    loss_matrix = calculate_loss(train_predicted_prob, y_train, c_fn, c_fp, c_tp, c_tn) \n",
    "    # finding optimal threshold:\n",
    "    opt_thr = list(loss_matrix[loss_matrix['loss'] == loss_matrix['loss'].min()]['prediction'])[0]\n",
    "    print(\"Optimal threshold at:\\t\",round(opt_thr,5))\n",
    "    loss = loss_matrix['loss'].min()\n",
    "    print(\"Model Loss:\", loss)\n",
    "    predicted_prob_opt = copy.deepcopy(predicted_prob)\n",
    "    predicted_prob_opt[predicted_prob_opt >  opt_thr] = 1\n",
    "    predicted_prob_opt[predicted_prob_opt <= opt_thr] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. Build the confusion matrix for the tests data for both the default and optimal thresholds\n",
    "if False:\n",
    "    def_cfm = metrics.confusion_matrix(y_test, predicted) \n",
    "    opt_cfm = metrics.confusion_matrix(y_test, predicted_prob_opt) # optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Display the confusion matrices\n",
    "if False:\n",
    "    plot_confusion_matrix(def_cfm,['bad', 'good'], \"Default Confusion Matrix\", 0)\n",
    "    plot_confusion_matrix(opt_cfm,['bad', 'good'], \"Loss-Optimized Confusion Matrix\", 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Random Forest is an ensemble learning classification method, which utilizes multiple decision-trees,<br>\n",
    "and a voting mechanism in order to classify each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Train the model (and predict)\n",
    "if False:\n",
    "    model = RandomForestClassifier(max_depth=md, max_features=mf, \n",
    "                                   criterion=criterion, min_samples_leaf = min_leaf, random_state=seed)\n",
    "    clf = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. Display the obtained model along with most relevant statistics\n",
    "if False:    \n",
    "    importance = model.feature_importances_\n",
    "    df_importance = pd.DataFrame(data=[list(cols_features), list(importance)]).transpose()\n",
    "    df_importance.columns = ['feature', 'importance']\n",
    "    df_importance = df_importance[df_importance['importance'] != 0]\n",
    "    # sort by feature importance\n",
    "    df_importance = df_importance.reindex(df_importance['importance'].abs().sort_values(inplace=False, ascending=False).index)\n",
    "    display(df_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Draw ROC Curve and calculate AUC\n",
    "if False:\n",
    "    predicted = clf.predict(X_test)\n",
    "    predicted_prob = clf.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(np.array(y_test), predicted_prob)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "    print (\"Area-Under-Curve:\", round(auc,4))\n",
    "    plot_ROC(fpr,tpr, fontsz, \"Receiver operating characteristic for Random Forest Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Calculate the total misclassification loss\n",
    "if False:\n",
    "    # finding the optimal values using the TRAIN-SET\n",
    "    train_predicted_prob = model.predict_proba(X_train)[:,1]\n",
    "    loss_matrix = calculate_loss(train_predicted_prob, y_train, c_fn, c_fp, c_tp, c_tn) \n",
    "    # finding optimal threshold:\n",
    "    opt_thr = list(loss_matrix[loss_matrix['loss'] == loss_matrix['loss'].min()]['prediction'])[0]\n",
    "    print(\"Optimal threshold at:\\t\",round(opt_thr,5))\n",
    "    loss = loss_matrix['loss'].min()\n",
    "    print(\"Model Loss:\", loss)\n",
    "    predicted_prob_opt = copy.deepcopy(predicted_prob)\n",
    "    predicted_prob_opt[predicted_prob_opt >  opt_thr] = 1\n",
    "    predicted_prob_opt[predicted_prob_opt <= opt_thr] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. Build the confusion matrix for the tests data for both the default and optimal thresholds\n",
    "if False:\n",
    "    def_cfm = metrics.confusion_matrix(y_test, predicted) \n",
    "    opt_cfm = metrics.confusion_matrix(y_test, predicted_prob_opt) # optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Display the confusion matrices\n",
    "if False:\n",
    "    plot_confusion_matrix(def_cfm,['bad', 'good'], \"Default Confusion Matrix\", 0)\n",
    "    plot_confusion_matrix(opt_cfm,['bad', 'good'], \"Loss-Optimized Confusion Matrix\", 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
