{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import io, os , sys, types\n",
    "import tabulate\n",
    "import copy\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import tree\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pydotplus\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "from helper_functions import *\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "fontsz = 12\n",
    "\n",
    "# ROC Curve and Cutoff Analysis:\n",
    "# https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/One_ROC_Curve_and_Cutoff_Analysis.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "fname_germancredit = r'dataset/German.Credit.csv'\n",
    "data_raw = pd.read_csv(fname_germancredit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>installment_commitment</th>\n",
       "      <th>residence_since</th>\n",
       "      <th>age</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>num_dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.903000</td>\n",
       "      <td>3271.258000</td>\n",
       "      <td>2.973000</td>\n",
       "      <td>2.845000</td>\n",
       "      <td>35.546000</td>\n",
       "      <td>1.407000</td>\n",
       "      <td>1.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.058814</td>\n",
       "      <td>2822.736876</td>\n",
       "      <td>1.118715</td>\n",
       "      <td>1.103718</td>\n",
       "      <td>11.375469</td>\n",
       "      <td>0.577654</td>\n",
       "      <td>0.362086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>1365.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>2319.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>3972.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>18424.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          duration  credit_amount  installment_commitment  residence_since          age  existing_credits  num_dependents\n",
       "count  1000.000000    1000.000000             1000.000000      1000.000000  1000.000000       1000.000000     1000.000000\n",
       "mean     20.903000    3271.258000                2.973000         2.845000    35.546000          1.407000        1.155000\n",
       "std      12.058814    2822.736876                1.118715         1.103718    11.375469          0.577654        0.362086\n",
       "min       4.000000     250.000000                1.000000         1.000000    19.000000          1.000000        1.000000\n",
       "25%      12.000000    1365.500000                2.000000         2.000000    27.000000          1.000000        1.000000\n",
       "50%      18.000000    2319.500000                3.000000         3.000000    33.000000          1.000000        1.000000\n",
       "75%      24.000000    3972.250000                4.000000         4.000000    42.000000          2.000000        1.000000\n",
       "max      72.000000   18424.000000                4.000000         4.000000    75.000000          4.000000        2.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_target = 'class'\n",
    "cols_numeric = list(data_raw.describe().columns.values)\n",
    "cols_categoric = list(set(data_raw.columns.values) - set(cols_numeric) - set([col_target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['property_magnitude',\n",
       " 'own_telephone',\n",
       " 'savings_status',\n",
       " 'credit_history',\n",
       " 'personal_status',\n",
       " 'employment',\n",
       " 'other_parties',\n",
       " 'other_payment_plans',\n",
       " 'purpose',\n",
       " 'housing',\n",
       " 'account_balance',\n",
       " 'foreign',\n",
       " 'job']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_categoric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>account_balance</th>\n",
       "      <th>'0&lt;=X&lt;200'</th>\n",
       "      <th>'&lt;0'</th>\n",
       "      <th>'&gt;=200'</th>\n",
       "      <th>'no account'</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>105</td>\n",
       "      <td>135</td>\n",
       "      <td>14</td>\n",
       "      <td>46</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>164</td>\n",
       "      <td>139</td>\n",
       "      <td>49</td>\n",
       "      <td>348</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>269</td>\n",
       "      <td>274</td>\n",
       "      <td>63</td>\n",
       "      <td>394</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "account_balance  '0<=X<200'  '<0'  '>=200'  'no account'   All\n",
       "class                                                         \n",
       "bad                     105   135       14            46   300\n",
       "good                    164   139       49           348   700\n",
       "All                     269   274       63           394  1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contingency table\n",
    "pd.crosstab(data_raw['class'], data_raw['account_balance'],  margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>account_balance</th>\n",
       "      <th>'0&lt;=X&lt;200'</th>\n",
       "      <th>'&lt;0'</th>\n",
       "      <th>'&gt;=200'</th>\n",
       "      <th>'no account'</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.153333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>0.234286</td>\n",
       "      <td>0.198571</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.497143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "account_balance  '0<=X<200'      '<0'   '>=200'  'no account'\n",
       "class                                                        \n",
       "bad                0.350000  0.450000  0.046667      0.153333\n",
       "good               0.234286  0.198571  0.070000      0.497143"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contingency table, ratios. Rows add-up to 100%\n",
    "pd.crosstab(data_raw['class'], data_raw['account_balance'],  margins=False, normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>account_balance</th>\n",
       "      <th>'0&lt;=X&lt;200'</th>\n",
       "      <th>'&lt;0'</th>\n",
       "      <th>'&gt;=200'</th>\n",
       "      <th>'no account'</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>0.390335</td>\n",
       "      <td>0.492701</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.116751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>0.609665</td>\n",
       "      <td>0.507299</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.883249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "account_balance  '0<=X<200'      '<0'   '>=200'  'no account'\n",
       "class                                                        \n",
       "bad                0.390335  0.492701  0.222222      0.116751\n",
       "good               0.609665  0.507299  0.777778      0.883249"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contingency table, ratios. Columns add-up to 100%\n",
    "pd.crosstab(data_raw['class'], data_raw['account_balance'],  margins=False, normalize='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 1.21890207229e-26 \t variable: account_balance\n"
     ]
    }
   ],
   "source": [
    "contingency = pd.crosstab(data_raw['class'], data_raw['account_balance'])\n",
    "c, pval, dof, expected = chi2_contingency(contingency)\n",
    "print(\"p-value:\",pval, '\\t variable:', 'account_balance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 2.85844157333e-05 \t variable: property_magnitude\n",
      "p-value: 0.278876154304 \t variable: own_telephone\n",
      "p-value: 2.76121423857e-07 \t variable: savings_status\n",
      "p-value: 1.27918729568e-12 \t variable: credit_history\n",
      "p-value: 0.0222380054693 \t variable: personal_status\n",
      "p-value: 0.00104545234914 \t variable: employment\n",
      "p-value: 0.0360559540272 \t variable: other_parties\n",
      "p-value: 0.00162931781865 \t variable: other_payment_plans\n",
      "p-value: 0.000115749100797 \t variable: purpose\n",
      "p-value: 0.000111674653746 \t variable: housing\n",
      "p-value: 1.21890207229e-26 \t variable: account_balance\n",
      "p-value: 0.0158307549029 \t variable: foreign\n",
      "p-value: 0.596581591884 \t variable: job\n"
     ]
    }
   ],
   "source": [
    "for col in cols_categoric:\n",
    "    contingency = pd.crosstab(data_raw['class'], data_raw[col])\n",
    "    c, pval, dof, expected = chi2_contingency(contingency)\n",
    "    print(\"p-value:\",pval, '\\t variable:', col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive Statistics for Numerical Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between numeric variables\n",
    "data_numeric = data_raw[cols_numeric].copy(deep=True)\n",
    "corr_mat = data_numeric.corr(method='pearson')\n",
    "cbar_ticks =np.linspace(-1,1,11)\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "plt.figure(figsize=[8,8])\n",
    "plt.xticks(fontsize=fontsz+2)\n",
    "plt.yticks(fontsize=fontsz+2)\n",
    "ax = sns.heatmap(corr_mat, cmap=cmap, vmin=-1, vmax=1, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.set_ticks(cbar_ticks)\n",
    "cbar.set_ticklabels(cbar_ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (corr_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brksCredits = np.linspace(0,80,11) # Bins for a nice looking histogram\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(data_raw['duration'], bins=brksCredits)\n",
    "plt.title('duration', fontsize=fontsz+4)\n",
    "plt.xlabel('Loan Period [Months]', fontsize=fontsz+2)\n",
    "plt.ylabel('Count', fontsize=fontsz+2)\n",
    "plt.xticks(fontsize=fontsz)\n",
    "plt.yticks(fontsize=fontsz)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.boxplot(data_raw['duration']) \n",
    "plt.title('duration boxplot', fontsize=fontsz+4)\n",
    "plt.xlabel('Credit Month', fontsize=fontsz+2) \n",
    "plt.ylabel('duration', fontsize=fontsz+2)\n",
    "plt.xticks(fontsize=fontsz)\n",
    "plt.yticks(fontsize=fontsz)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "Dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Number of columns before dummy-variables:\\t\", len(data_raw.columns.values))\n",
    "for i in cols_categoric:\n",
    "    dummy_ranks = pd.get_dummies(data_raw[i], prefix=i)\n",
    "    data_raw = data_raw.join(dummy_ranks)\n",
    "    # dropping the original categoric column (not needed - it was replaced by dummy columns)\n",
    "    data_raw = data_raw.drop(i, 1) \n",
    "    \n",
    "# all feature, numeric, and categoric (now dummified)\n",
    "cols_features = list(set(data_raw.columns.values) - set([col_target])) \n",
    "print (\"Number of columns after dummy-variables:\\t\", len(data_raw.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replacing calss variable with numeric values (for convinience)\n",
    "data_raw['class'].replace('bad', 0, inplace=True)\n",
    "data_raw['class'].replace('good', 1, inplace=True)\n",
    "data_raw['class'] = pd.to_numeric(data_raw['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed\n",
    "seed = 1017\n",
    "random.seed(seed)\n",
    "frac_train = 0.8 # 80% of the data is used for training\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(data_raw[cols_features], data_raw[col_target], test_size=(1-frac_train), random_state=seed)\n",
    "    \n",
    "train_b = sum(y_train == 0)\n",
    "train_g = sum(y_train == 1)\n",
    "test_b = sum(y_test == 0)\n",
    "test_g = sum(y_test == 1)\n",
    "print (\"Class ratios between each set:\")\n",
    "print (\"Trainset\")\n",
    "print (\"\\t\\tNormal class (good):\", 100*train_g/len(y_train), \"%\\t\", \"Target class (bad):\", 100*train_b/len(y_train),\"%\")\n",
    "print (\"Testset\")\n",
    "print (\"\\t\\tNormal class (good):\", 100*test_g/len(y_test), \"%\\t\", \"Target class (bad):\", 100*test_b/len(y_test),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set Misclassification loss weights\n",
    "c_tn = 0 # weight of true-negative\n",
    "c_tp = 0 # weight of true-positive\n",
    "c_fn = 1 # weight of false negative\n",
    "c_fp = 5 # weight of false positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model\n",
    "More about Logistic Regression examples in python can be found here:<br>\n",
    "http://blog.yhat.com/posts/logistic-regression-python-rodeo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean(y_train - model.predict(X_train)) ** 2\n",
    "print (\"Mean Square Error: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coefficients = model.coef_[0]\n",
    "df_lgm_coeffs = pd.DataFrame(data=model_coefficients, index=cols_features, columns=['LGM_coeff'])\n",
    "# sort by coefficients absolute value\n",
    "df_lgm_coeffs = df_lgm_coeffs.reindex(df_lgm_coeffs.LGM_coeff.abs().sort_values(ascending=False).index)\n",
    "display(df_lgm_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)\n",
    "predicted_prob = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(np.array(y_test), predicted_prob)\n",
    "auc = metrics.auc(fpr,tpr)\n",
    "print (\"Area-Under-Curve:\", round(auc,4))\n",
    "# plot_ROC() is defined in helper_functions.py\n",
    "plot_ROC(fpr,tpr, fontsz, 'Receiver operating characteristic for Logistic Regression Model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the optimal values using the TRAIN-SET\n",
    "train_predicted_prob = model.predict_proba(X_train)[:,1]\n",
    "loss_matrix = calculate_loss(train_predicted_prob, y_train, c_fn, c_fp, c_tp, c_tn) \n",
    "# finding optimal threshold:\n",
    "opt_thr = list(loss_matrix[loss_matrix['loss'] == loss_matrix['loss'].min()]['prediction'])[0]\n",
    "print(\"Optimal threshold at:\\t\",round(opt_thr,5))\n",
    "print(\"Model Loss:\", loss_matrix['loss'].min())\n",
    "loss = loss_matrix['loss'].min()\n",
    "predicted_prob_opt = copy.deepcopy(predicted_prob)\n",
    "predicted_prob_opt[predicted_prob_opt >  opt_thr] = 1\n",
    "predicted_prob_opt[predicted_prob_opt <= opt_thr] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def_cfm = metrics.confusion_matrix(y_test, predicted) # default confusion matrix, default threshold = 0.5\n",
    "opt_cfm = metrics.confusion_matrix(y_test, predicted_prob_opt) # optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(def_cfm,['bad', 'good'], \"Default Confusion Matrix\", 0)\n",
    "plot_confusion_matrix(opt_cfm,['bad', 'good'], \"Loss-Optimized Confusion Matrix\", 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5), facecolor='white')\n",
    "plt.plot(loss_matrix['prediction'], loss_matrix['loss'], 'o-')\n",
    "plt.title('Loss function for various thresholds and confusion matrices', fontsize=fontsz+4)\n",
    "plt.xlabel('Threshold', fontsize=fontsz+4)\n",
    "plt.ylabel('Loss', fontsize=fontsz+4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gnb = BernoulliNB()\n",
    "model = gnb.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "predicted_prob = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_coefficients = model.coef_[0]\n",
    "df_coeffs = pd.DataFrame(data=[list(cols_features), list(model_coefficients)]).transpose()\n",
    "df_coeffs.columns = ['feature', 'coeff']\n",
    "# sort by coefficients absolute value (log probability of the positive class)\n",
    "df_coeffs = df_coeffs.reindex(df_coeffs['coeff'].abs().sort_values(inplace=False, ascending=True).index)\n",
    "display(df_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(np.array(y_test), predicted_prob)\n",
    "auc = metrics.auc(fpr,tpr)\n",
    "print (\"Area-Under-Curve:\", round(auc,4))\n",
    "plot_ROC(fpr,tpr, fontsz, 'Receiver operating characteristic for Naive Bayes Model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the optimal values using the TRAIN-SET\n",
    "train_predicted_prob = model.predict_proba(X_train)[:,1]\n",
    "loss_matrix = calculate_loss(train_predicted_prob, y_train, c_fn, c_fp, c_tp, c_tn) \n",
    "# finding optimal threshold:\n",
    "opt_thr = list(loss_matrix[loss_matrix['loss'] == loss_matrix['loss'].min()]['prediction'])[0]\n",
    "print(\"Optimal threshold at:\\t\",round(opt_thr,5))\n",
    "loss = loss_matrix['loss'].min()\n",
    "print(\"Model Loss:\", loss)\n",
    "predicted_prob_opt = copy.deepcopy(predicted_prob)\n",
    "predicted_prob_opt[predicted_prob_opt >  opt_thr] = 1\n",
    "predicted_prob_opt[predicted_prob_opt <= opt_thr] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def_cfm = metrics.confusion_matrix(y_test, predicted) \n",
    "opt_cfm = metrics.confusion_matrix(y_test, predicted_prob_opt) # optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(def_cfm,['bad', 'good'], \"Default Confusion Matrix\", 0)\n",
    "plot_confusion_matrix(opt_cfm,['bad', 'good'], \"Loss-Optimized Confusion Matrix\", 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "Decision Trees is a recursive-repartitioning technique, which is used to recursively split the data in order to create nodes that are<br>\n",
    "purer. A pure node is a node that consists of only 1-class of those existing in the data.<br>\n",
    "In our context, a pure node would be composed of either all-\"bad\" or all-\"good\" classes.<br>\n",
    "The advantages of DT is that it produces rules that are easy to follow, and human-readable, in contrast to other \"black-box\" algorithms, such as Random-Forest<br>\n",
    "DTs however, are prone to overfitting, which is why we need to use some parameters to avoid such behavior.<br>\n",
    "As with __Logistic Regression__, __DT__s also require categorical features to be dummified.<br>\n",
    "1. Based on what we discussed, can you offer an intuition about why DTs tend to overfit?\n",
    "2. [Advanced] Can you offer some ways to avoid overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "md = 18                    # maximum tree depth\n",
    "mf = len(cols_features)    # maximum number of features to consider\n",
    "min_leaf = 10\n",
    "criterion = 'entropy'\n",
    "model = tree.DecisionTreeClassifier(max_depth=md, max_features=mf, criterion=criterion, \n",
    "                                    min_samples_leaf=min_leaf, random_state=seed)\n",
    "\n",
    "clf = model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "predicted_prob = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = model.feature_importances_\n",
    "df_importance = pd.DataFrame(data=[list(cols_features), list(importance)]).transpose()\n",
    "df_importance.columns = ['feature', 'importance']\n",
    "df_importance = df_importance[df_importance['importance'] != 0]\n",
    "# sort by feature importance\n",
    "df_importance = df_importance.reindex(df_importance['importance'].abs().sort_values(inplace=False, ascending=False).index)\n",
    "display(df_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize the tree\n",
    "#write_Tree('dataset', clf, cols_features) # can be used only for small trees (<=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(np.array(y_test), predicted_prob)\n",
    "auc = metrics.auc(fpr,tpr)\n",
    "print (\"Area-Under-Curve:\", round(auc,4))\n",
    "plot_ROC(fpr,tpr, fontsz, \"Receiver operating characteristic for Decision Tree Model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the optimal values using the TRAIN-SET\n",
    "train_predicted_prob = model.predict_proba(X_train)[:,1]\n",
    "loss_matrix = calculate_loss(train_predicted_prob, y_train, c_fn, c_fp, c_tp, c_tn) \n",
    "# finding optimal threshold:\n",
    "opt_thr = list(loss_matrix[loss_matrix['loss'] == loss_matrix['loss'].min()]['prediction'])[0]\n",
    "print(\"Optimal threshold at:\\t\",round(opt_thr,5))\n",
    "loss = loss_matrix['loss'].min()\n",
    "print(\"Model Loss:\", loss)\n",
    "predicted_prob_opt = copy.deepcopy(predicted_prob)\n",
    "predicted_prob_opt[predicted_prob_opt >  opt_thr] = 1\n",
    "predicted_prob_opt[predicted_prob_opt <= opt_thr] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def_cfm = metrics.confusion_matrix(y_test, predicted) \n",
    "opt_cfm = metrics.confusion_matrix(y_test, predicted_prob_opt) # optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(def_cfm,['bad', 'good'], \"Default Confusion Matrix\", 0)\n",
    "plot_confusion_matrix(opt_cfm,['bad', 'good'], \"Loss-Optimized Confusion Matrix\", 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Random Forest is an ensemble learning classification method, which utilizes multiple decision-trees,<br>\n",
    "and a voting mechanism in order to classify each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(max_depth=md, max_features=mf, \n",
    "                               criterion=criterion, min_samples_leaf = min_leaf, random_state=seed)\n",
    "clf = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = model.feature_importances_\n",
    "df_importance = pd.DataFrame(data=[list(cols_features), list(importance)]).transpose()\n",
    "df_importance.columns = ['feature', 'importance']\n",
    "df_importance = df_importance[df_importance['importance'] != 0]\n",
    "# sort by feature importance\n",
    "df_importance = df_importance.reindex(df_importance['importance'].abs().sort_values(inplace=False, ascending=False).index)\n",
    "display(df_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_test)\n",
    "predicted_prob = clf.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np.array(y_test), predicted_prob)\n",
    "auc = metrics.auc(fpr,tpr)\n",
    "print (\"Area-Under-Curve:\", round(auc,4))\n",
    "plot_ROC(fpr,tpr, fontsz, \"Receiver operating characteristic for Random Forest Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the optimal values using the TRAIN-SET\n",
    "train_predicted_prob = model.predict_proba(X_train)[:,1]\n",
    "loss_matrix = calculate_loss(train_predicted_prob, y_train, c_fn, c_fp, c_tp, c_tn) \n",
    "# finding optimal threshold:\n",
    "opt_thr = list(loss_matrix[loss_matrix['loss'] == loss_matrix['loss'].min()]['prediction'])[0]\n",
    "print(\"Optimal threshold at:\\t\",round(opt_thr,5))\n",
    "loss = loss_matrix['loss'].min()\n",
    "print(\"Model Loss:\", loss)\n",
    "predicted_prob_opt = copy.deepcopy(predicted_prob)\n",
    "predicted_prob_opt[predicted_prob_opt >  opt_thr] = 1\n",
    "predicted_prob_opt[predicted_prob_opt <= opt_thr] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def_cfm = metrics.confusion_matrix(y_test, predicted) \n",
    "opt_cfm = metrics.confusion_matrix(y_test, predicted_prob_opt) # optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(def_cfm,['bad', 'good'], \"Default Confusion Matrix\", 0)\n",
    "plot_confusion_matrix(opt_cfm,['bad', 'good'], \"Loss-Optimized Confusion Matrix\", 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model AUC, loss:\n",
    "# Logistic Regression:    0.81, 354\n",
    "# Naive Bayes:            0.81, 395\n",
    "# Decision Tree:          0.71, 271\n",
    "# Random Forest:          0.77, 241 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
